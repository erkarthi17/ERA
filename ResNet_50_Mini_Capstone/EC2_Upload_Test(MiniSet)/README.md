# ğŸ§  ResNet-50 Training from Scratch on AWS EC2 (MiniSet Credit Submission)

This project implements a **ResNet-50** model trained **from scratch** on a small subset of ImageNet (**Imagenette2**) using **PyTorch**.  
It serves as the **credit request submission** for the â€œResNet-50 from Scratch on ImageNet 1Kâ€ assignment under TSAI, demonstrating a complete, functional deep learning pipeline on an AWS GPU instance.

---

## ğŸš€ Project Overview

**Core Highlights:**

- ğŸ§© **ResNet-50 Architecture** â€” Implemented from scratch in PyTorch.  
- ğŸ”„ **Training from Scratch** â€” No pre-trained weights are used.  
- âš™ï¸ **PyTorch Framework** â€” End-to-end training and evaluation pipeline.  
- ğŸ“¦ **Hugging Face Datasets Integration** â€” Efficient dataset handling via `data_hf.py`.  
- â˜ï¸ **AWS EC2 Optimized** â€” Automated setup via `setup_ec2.sh` for GPU-backed instances (e.g., `g4dn.2xlarge`).  
- âš¡ **Mixed Precision Training** â€” Supports NVIDIA Apex or PyTorch AMP for faster and memory-efficient training.  
- ğŸ§¾ **Logging & Checkpointing** â€” Saves model states and logs for resumption and monitoring.

---

## ğŸ¯ Assignment Context

This submission demonstrates the ability to:
1. Set up and train a **ResNet-50 model from scratch** on EC2.
2. Achieve a working end-to-end training pipeline using Imagenette2 as a mini ImageNet subset.

Upon receiving AWS credits, the next goal is to **scale training to the full ImageNet-1K dataset**, targeting:
- ğŸ¯ **75% Top-1 accuracy**
- â­ **81% Top-1 accuracy** (for bonus points)

> **Note:** No pre-trained weights or transfer learning techniques are used â€” this is a pure â€œtrain from scratchâ€ setup.

---

## ğŸ§° Setup & Usage Guide

### âœ… Prerequisites

- AWS **EC2 instance** with GPU (Recommended: `g4dn.2xlarge`)
- **Deep Learning AMI (Ubuntu)** with CUDA and PyTorch pre-installed  
- **Git** and **SSH access** configured
- **Python 3.8+**

---

### 1ï¸âƒ£ Clone the Repository

```bash
# If not already cloned
git clone https://github.com/erkarthi17/ERA/tree/6a73600b8317b0b3aa690a2c0d899549452c22a3/ResNet_50_Mini_Capstone/EC2_Upload_Test(MiniSet)

# Navigate to this project directory
cd ResNet_50_Mini_Capstone/EC2_Upload_Test\(MiniSet\)
```

---

### 2ï¸âƒ£ Set Up Your Environment

Run the setup script to configure everything automatically:

```bash
chmod +x setup_ec2.sh
bash ./setup_ec2.sh
```

This script will:
- Update system packages
- Install Python, `pip`, and `venv`
- Create and activate a virtual environment (`venv`)
- Install dependencies from `requirements.txt`
- Set up `checkpoints/`, `logs/`, and `data/` directories

> âš ï¸ Always use `bash ./setup_ec2.sh` (not `sh`) to ensure correct execution.

---

### 3ï¸âƒ£ Activate Virtual Environment (for New Sessions)

```bash
source venv/bin/activate
```

---

### 4ï¸âƒ£ Data Setup

This project uses **Imagenette2**, a lightweight subset of ImageNet.  
Place the dataset inside the `./imagenette2` folder â€” the `data_hf.py` loader will automatically detect it.

> ğŸ’¡ No need to manually download ImageNet or specify `--data-root`.

---

### 5ï¸âƒ£ Run a Quick Training Test

Run a short training cycle (2â€“5 epochs) to verify your setup:

```bash
python train_hf.py --epochs 2 --batch-size 64
```

- Adjust `--epochs` for longer runs (e.g., `--epochs 5`)
- Adjust `--batch-size` based on GPU memory

---

### 6ï¸âƒ£ Monitor Training Progress

In a **new SSH terminal**, connect to your EC2 instance:

```bash
ssh -i your-key.pem ubuntu@your-ec2-ip
```

Then monitor training via:

#### ğŸ§  GPU Usage
```bash
watch -n 1 nvidia-smi
```

#### ğŸ“ Live Logs
```bash
tail -f ../logs/resnet50_imagenet_*.log
```

#### ğŸ“Š TensorBoard (optional)
```bash
tensorboard --logdir=../logs --host=localhost --port=6006
```
Access from your browser at:  
ğŸ‘‰ `http://<your-ec2-ip>:6006`

---

## ğŸ“‚ Repository Structure

```bash
.
â”œâ”€â”€ config.py              # Configuration settings
â”œâ”€â”€ data_hf.py             # Hugging Face dataset loader
â”œâ”€â”€ imagenette2/           # Imagenette2 dataset folder
â”œâ”€â”€ model.py               # ResNet-50 model definition
â”œâ”€â”€ requirements.txt       # Dependencies list
â”œâ”€â”€ setup_ec2.sh           # EC2 environment setup script
â”œâ”€â”€ train_hf.py            # Main training script
â”œâ”€â”€ utils.py               # Logging, metrics, checkpointing utilities
â””â”€â”€ README.md              # Project documentation (this file)
```

---

## ğŸ§¾ Submission Components

| Component | Description |
|------------|-------------|
| ğŸ§  **GitHub Repo Link** | https://github.com/erkarthi17/ERA/tree/6a73600b8317b0b3aa690a2c0d899549452c22a3/ResNet_50_Mini_Capstone/EC2_Upload_Test(MiniSet) |
| ğŸ¤— **Hugging Face Spaces Link** | Will be added post ImageNet 1K Build |
| ğŸ¥ **YouTube Demo Video** | Same as above |
| ğŸ“œ **Markdown Log File** | `FULL_TRAINING_LOGS.md` â€” consolidated logs from all epochs |
| ğŸ–¥ï¸ **EC2 Screenshot** | Attached in the Mail |

---

## ğŸ§© Quick Command Reference

```bash
# Setup
chmod +x setup_ec2.sh
bash ./setup_ec2.sh

# Activate Environment
source venv/bin/activate

# Run Training
python train_hf.py --epochs 2 --batch-size 64

# Monitor GPU
watch -n 1 nvidia-smi

# View Logs
tail -f ../logs/resnet50_imagenet_*.log
```

---

## ğŸ Next Steps

Once AWS credits are approved:
- Scale up to **ImageNet-1k**
- Increase training duration & hyperparameter tuning
- Log results for full-credit submission

---

**Author(s):** Karthick Kannan
**Institution:** TSAI â€“ The School of AI  
**Project:** ResNet-50 from Scratch â€“ EC2 MiniSet Credit Submission